第1章　基础知识　1
1.1　Hadoop和MapReduce综述　3
1.2　Hadoop生态系统中的Hive　6
1.2.1　Pig　8
1.2.2　HBase　8
1.2.3　Cascading、Crunch及其他　9
1.3　Java和Hive：词频统计算法　11
1.4　后续事情　13

第2章　基础操作　14
2.1　安装预先配置好的虚拟机　14
2.2　安装详细步骤　15
2.2.1　装Java　16
2.2.2　安装Hadoop　17
2.2.3　本地模式、伪分布式模式和分布式模式　18
2.2.4　测试Hadoop　19
2.2.5　安装Hive　21
2.3　Hive内部是什么　22
2.4　启动Hive　22
2.5　配置Hadoop环境　24
2.5.1　本地模式配置　24
2.5.2　分布式模式和伪分布式模式配置　26
2.5.3　使用JDBC连接元数据　27
2.6　Hive命令　29
2.7　命令行界面　30
2.7.1　CLI 选项　30
2.7.2　变量和属性　31
2.7.3　Hive中“一次使用”命令　34
2.7.4　从文件中执行Hive查询　35
2.7.5　hiverc文件　36
2.7.6　使用Hive CLI的更多介绍　36
2.7.7　查看操作命令历史　37
2.7.8　执行shell命令　37
2.7.9　在Hive内使用Hadoop的dfs命令　38
2.7.10　Hive脚本中如何进行注释　38
2.7.11　显示字段名称　38

第3章　数据类型和文件格式　40
3.1　基本数据类型　40
3.2　集合数据类型　42
3.3　文本文件数据编码　44
3.4　读时模式　47

第4章　HiveQL：数据定义　48
4.1　Hive中的数据库　48
4.2　修改数据库　52
4.3　创建表　52
4.3.1　管理表　56
4.3.2　外部表　56
4.4　分区表、管理表　57
4.4.1　外部分区表　61
4.4.2　自定义表的存储格式　63
4.5　删除表　66
4.6　修改表　66
4.6.1　表重命名　67
4.6.2　增加、修改和删除表分区　67
4.6.3　修改列信息　68
4.6.4　增加列　68
4.6.5　删除或者替换列　68
4.6.6　修改表属性　69
4.6.7　修改存储属性　69
4.6.8　众多的修改表语句　70

第5章　HiveQL：数据操作　71
5.1　向管理表中装载数据　71
5.2　通过查询语句向表中插入数据　73
5.3　单个查询语句中创建表并加载数据　76
5.4　导出数据　76

第6章　HiveQL：查询　78
6.1　SELECT…FROM语句　78
6.1.1　使用正则表达式来指定列　80
6.1.2　使用列值进行计算　81
6.1.3　算术运算符　81
6.1.4　使用函数　82
6.1.5　LIMIT语句　93
6.1.6　列别名　93
6.1.7　嵌套SELECT语句　93
6.1.8　CASE…WHEN…THEN 句式　93
6.1.9　什么情况下Hive可以避免进行MapReduce　94
6.2　WHERE语句　95
6.2.1　谓词操作符　96
6.2.2　关于浮点数比较　97
6.2.3　LIKE和RLIKE　98
6.3　GROUP BY 语句　99
6.4　JOIN语句　100
6.4.1　INNER JOIN　100
6.4.2　JOIN优化　103
6.4.3　LEFT OUTER JOIN　104
6.4.4　OUTER JOIN　104
6.4.5　RIGHT OUTER JOIN　106
6.4.6　FULL OUTER JOIN　107
6.4.7　LEFT SEMI-JOIN　107
6.4.8　笛卡尔积JOIN　108
6.4.9　map-side JOIN　108
6.5　ORDER BY和SORT BY　110
6.6　含有SORT BY 的DISTRIBUTE BY　111
6.7　CLUSTER BY　112
6.8　类型转换　112
6.9　抽样查询　113
6.9.1　数据块抽样　114
6.9.2　分桶表的输入裁剪　114
6.10　UNION ALL　115

第7章　HiveQL：视图　117
7.1　使用视图来降低查询复杂度　117
7.2　使用视图来限制基于条件过滤的数据　118
7.3　动态分区中的视图和map类型　118
7.4　视图零零碎碎相关的事情　119

第8章　HiveQL：索引　122
8.1　创建索引　122
8.2　重建索引　124
8.3　显示索引　124
8.4　删除索引　124
8.5　实现一个定制化的索引处理器　125

第9章　模式设计　126
9.1　按天划分的表　126
9.2　关于分区　127
9.3　唯一键和标准化　128
9.4　同一份数据多种处理　129
9.5　对于每个表的分区　130
9.6　分桶表数据存储　131
9.7　为表增加列　132
9.8　使用列存储表　133
9.8.1　重复数据　133
9.8.2　多列　133
9.9　(几乎)总是使用压缩　134

第10章　调优　135
10.1　使用EXPLAIN　135
10.2　EXPLAIN EXTENDED　138
10.3　限制调整　139
10.4　JOIN优化　140
10.5　本地模式　140
10.6　并行执行　141
10.7　严格模式　141
10.8　调整mapper和reducer个数　142
10.9　JVM重用　144
10.10　索引　145
10.11　动态分区调整　145
10.12　推测执行　146
10.13　单个MapReduce中多个GROUP BY　147
10.14　虚拟列　147

第11章　其他文件格式和压缩方法　149
11.1　确定安装编解码器　149
11.2　选择一种压缩编/解码器　150
11.3　开启中间压缩　151
11.4　最终输出结果压缩　152
11.5　sequence file存储格式　152
11.6　使用压缩实践　153
11.7　存档分区　157
11.8　压缩：包扎　159

第12章　开发　160
12.1　修改Log4J属性　160
12.2　连接Java调试器到Hive　161
12.3　从源码编译Hive　161
12.3.1　执行Hive测试用例　162
12.3.2　执行hook　163
12.4　配置Hive和Eclipse　163
12.5　Maven工程中使用Hive　164
12.6　Hive中使用hive_test进行单元测试　165
12.7　新增的插件开发工具箱(PDK)　167

第13章　函数　168
13.1　发现和描述函数　168
13.2　调用函数　169
13.3　标准函数　169
13.4　聚合函数　169
13.5　表生成函数　170
13.6　一个通过日期计算其星座的UDF　171
13.7　UDF与GenericUDF　174
13.8　不变函数　177
13.9　用户自定义聚合函数　177
13.10　用户自定义表生成函数　183
13.10.1　可以产生多行数据的UDTF　183
13.10.2　可以产生具有多个字段的单行数据的UDTF　185
13.10.3　可以模拟复杂数据类型的UDTF　185
13.11　在 UDF中访问分布式缓存　188
13.12　以函数的方式使用注解　190
13.12.1　定数性(deterministic)标注　191
13.12.2　状态性(stateful)标注　191
13.12.3　唯一性　191
13.13　宏命令　191

第14章　Streaming　193
14.1　恒等变换　194
14.2　改变类型　194
14.3　投影变换　194
14.4　操作转换　195
14.5　使用分布式内存　195
14.6　由一行产生多行　196
14.7　使用streaming进行聚合计算　197
14.8　CLUSTER BY、DISTRIBUTE BY、SORT BY　198
14.9　GenericMR Tools for Streaming to Java　201
14.10　计算cogroup　203

第15章　自定义Hive文件和记录格式　204
15.1　文件和记录格式　204
15.2　阐明CREATE TABLE句式　204
15.3　文件格式　206
15.3.1　SequenceFile　207
15.3.2　RCfile　207
15.3.3　示例自定义输入格式：DualInputFormat　208
15.4　记录格式：SerDe　210
15.5　CSV和TSV SerDe　211
15.6　ObjectInspector　212
15.7　Thing Big Hive Reflection ObjectInspector　212
15.8　XML UDF　212
15.9　XPath相关的函数　213
15.10　JSON SerDe　214
15.11　Avro Hive SerDe　215
15.11.1　使用表属性信息定义Avro Schema　215
15.11.2　从指定URL中定义Schema　216
15.11.3　进化的模式　216
15.12　二进制输出　217

第16章　Hive的Thrift服务　218
16.1　启动Thrift Server　218
16.2　配置Groovy使用HiveServer　219
16.3　连接到HiveServer　219
16.4　获取集群状态信息　220
16.5　结果集模式　220
16.6　获取结果　220
16.7　获取执行计划　221
16.8　元数据存储方法　221
16.9　管理HiveServer　222
16.9.1　生产环境使用HiveServer　223
16.9.2　清理　224
16.10　Hive ThriftMetastore　224
16.10.1　ThriftMetastore 配置　224
16.10.2　客户端配置　224

第17章　存储处理程序和NoSQL　226
17.1　Storage Handler Background　226
17.2　HiveStorageHandler　227
17.3　HBase　227
17.4　Cassandra　229
17.4.1　静态列映射(Static Column Mapping)　229
17.4.2　为动态列转置列映射　229
17.4.3　Cassandra SerDe Properties　229
17.5　DynamoDB　230

第18章　安全　232
18.1　和Hadoop安全功能相结合　233
18.2　使用Hive进行验证　233
18.3　Hive中的权限管理　234
18.3.1　用户、组和角色　235
18.3.2　Grant 和 Revoke权限　236
18.4　分区级别的权限　238
18.5　自动授权　239

第19章　锁　241
19.1　Hive结合Zookeeper支持锁功能　241
19.2　显式锁和独占锁　244

第20章　Hive和Oozie整合　245
20.1　Oozie提供的多种动作(Action)　245
20.2　一个只包含两个查询过程的工作流示例　247
20.3　Oozie 网页控制台　248
20.4　工作流中的变量　248
20.5　获取输出　249
20.6　获取输出到变量　250

第21章　Hive和亚马逊网络服务系统(AWS)　251
21.1　为什么要弹性MapReduce　251
21.2　实例　251
21.3　开始前的注意事项　252
21.4　管理自有EMR Hive集群　252
21.5　EMR Hive上的Thrift Server服务　253
21.6　EMR上的实例组　253
21.7　配置EMR集群　254
21.7.1　部署hive-site.xml文件　254
21.7.2　部署.hiverc脚本　255
21.7.3　建立一个内存密集型配置　255
21.8　EMR上的持久层和元数据存储　256
21.9　EMR集群上的HDFS和S3　257
21.10　在S3上部署资源、配置和辅助程序脚本　258
21.11　S3上的日志　258
21.12　现买现卖　258
21.13　安全组　260
21.14　EMR和EC2以及Apache Hive的比较　260
21.15　包装　261

第22章　HCatalog　262
22.1　介绍　262
22.2　MapReduce　263
22.2.1　读数据　263
22.2.2　写数据　265
22.3　命令行　268
22.4　安全模型　269
22.5　架构　270

第23章　案例研究　271
23.1　m6d.com(Media6Degrees)　271
23.1.1　M 6D的数据科学，使用Hive和R　271
23.1.2　M6D UDF伪随机　275
23.1.3　M6D如何管理多MapReduce集群间的Hive数据访问　280
23.2　Outbrain　284
23.2.1　站内线上身份识别　284
23.2.2　计算复杂度　287
23.2.3　会话化　288
23.3　NASA喷气推进实验室　295
23.3.1　区域气候模型评价系统　295
23.3.2　我们的经验：为什么使用Hive　297
23.3.3　解决这些问题我们所面临的挑战　298
23.4　Photobucket　299
23.4.1　Photobucket 公司的大数据应用情况　299
23.4.2　Hive所使用的硬件资源信息　300
23.4.3　Hive提供了什么　300
23.4.4　Hive支持的用户有哪些　300
23.5　SimpleReach　300
23.6　Experiences and Needs from the Customer Trenches　303
23.6.1　介绍　303
23.6.2　Customer Trenches的用例　304

术语词汇表　312